{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6387de74-7f19-446c-9c10-3d201a270a87",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "\n",
    "### Hands-on 2a: MNIST\n",
    "Filippo Vicentini and Giuseppe Carleo\n",
    "\n",
    "The objective of this hands-on is to write and optimise an image-classifier that identifies handwritten digits.\n",
    "\n",
    "We will use for this the MNIST dataset\n",
    "\n",
    "![title](images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7895a56-6b30-49bc-b07e-1fe5a6a00b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "#!pip install tensorflow_datasets flax jax optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561535f1-4d9a-4908-bbb7-e63c94d22d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions (don't worry. you don't need to understand this one)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_img(img, ax=None, title=None):\n",
    "  \"\"\"Shows a single image.\"\"\"\n",
    "  if ax is None:\n",
    "    ax = plt.gca()\n",
    "  ax.imshow(img[..., 0], cmap='gray')\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  if title:\n",
    "    ax.set_title(title)\n",
    "\n",
    "def show_img_grid(imgs, titles):\n",
    "  \"\"\"Shows a grid of images.\"\"\"\n",
    "  n = int(np.ceil(len(imgs)**.5))\n",
    "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
    "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "    show_img(img, axs[i // n][i % n], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241cfd9e-6a5e-4257-b3b5-2e7bad914a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e0f68-c1d0-4ce1-9ad1-65b6e47684d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55c5988d-c3c3-43d0-abc8-6ceb1c09054d",
   "metadata": {},
   "source": [
    "## 1 - Setting up the dataset\n",
    "First of all, we need to download the dataset.\n",
    "\n",
    "The MNIST dataset is a standard dataset composed of several 28x28 black/white images representing numbers, and a label corresponding to the number that is represented there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e05be1-0fd8-4562-8251-f8caa0576d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Tensorflow datasets to download and import data in a simple numpy-tensor format\n",
    "# It's just handy. You could use anything else.\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Specify the dataset we are interested in\n",
    "ds_builder = tfds.builder('mnist')\n",
    "# Download the data\n",
    "ds_builder.download_and_prepare()\n",
    "# Get the whole dataset's train set\n",
    "train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "\n",
    "train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "\n",
    "# convert to bool\n",
    "train_ds['image'] = train_ds['image']>=0.5\n",
    "test_ds['image'] = test_ds['image']>=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b5869-071c-4431-b830-fd837948577d",
   "metadata": {},
   "source": [
    "The dataset is split into two sub-sets: the training dataset that we will use to 'train' our model, and the 'test' dataset, which the model *never sees* during training, but that we use to check that the model performs well.\n",
    "\n",
    "This is to verify that the model does not simply learn _by heart_ the images in the training dataset, but that it actually _learns_ to generalize and works correctly with images that he did not see before.\n",
    "\n",
    "We can inspect the shape of the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6521ad-6be7-46ab-9cf4-28d24da2d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset keys: dict_keys(['image', 'label'])\n",
      "The training dataset has shape: (60000, 28, 28, 1) and dtype bool\n",
      "The test     dataset has shape: (10000, 28, 28, 1) and dtype bool\n",
      "\n",
      "The training labels have shape: (60000,) and dtype int64\n",
      "The test     labels have shape: (10000,) and dtype int64\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset keys:\", train_ds.keys())\n",
    "print(f\"The training dataset has shape: {train_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
    "print(f\"The test     dataset has shape: {test_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
    "print(\"\")\n",
    "print(f\"The training labels have shape: {train_ds['label'].shape} and dtype {train_ds['label'].dtype}\")\n",
    "print(f\"The test     labels have shape: {test_ds['label'].shape} and dtype {test_ds['label'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15665ab5-cb0c-4478-a48e-e0515cbe4fef",
   "metadata": {},
   "source": [
    "We can visualize it to understand it a bit more, using an utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6146cb7-be9d-4206-8b60-ae27699f0444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img_grid(\n",
    "    [train_ds['image'][idx] for idx in range(9)],\n",
    "    [f'label={train_ds[\"label\"][idx]}' for idx in range(9)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9f1e8-b449-4589-a826-3dd5771db7ce",
   "metadata": {},
   "source": [
    "We have seen that the data is stored in uint8 (an *unsigned* 8-bit integer which can take values from 0 to 255 ).\n",
    "\n",
    "However it is often preferable when working with Neural Networks to work with floating-point values with values around 0 and variance approximately 1. The reasons are 2:\n",
    "\n",
    " - modern CPUs (and to an extent GPUs) are often faster at working with batches (blocks) of floating-point numbers rather than integers [caveats apply]\n",
    " - Many nonlinear functions used in machine-learning have the nonlinear crossover aroud ~0 or ~1/2, so we want our data to be spread around those values\n",
    " - Most research about how to initialize neural-network layers assumes that the input data has mean 0 and variance 1, so to exploit those results we have to rescale our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf695fb-0fab-49f3-81fd-9a23fc7ea311",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e56e14-2a4e-4fad-9d47-809ba4b0a354",
   "metadata": {},
   "source": [
    "## 2 - The model (Neural Network)\n",
    "\n",
    "We want now to define the Model.\n",
    "We will use Flax to do that.\n",
    "\n",
    "We want our network to return a probability distribution for the input to correspond to one of several output labels.\n",
    "\n",
    "e.g: if $x$ is an image, then $f : \\mathbb{R}^{28\\times 28}\\rightarrow \\mathbb{R}^{10}$ and $f^{(i)}(x)$ is the probability that the image $x$ represents a $i\\in[0,9]$\n",
    "\n",
    "To make the output of the network a probability distribution, we can use a softmax function, defined as\n",
    "\n",
    "$$\n",
    "\\sigma_i(x) = \\frac{e^{x_i}}{\\sum_i^K e^{x_i} }  \\text{   for  } i\\in [1,K] \\text{ and } x\\in\\mathbb{R}^K\n",
    "$$\n",
    "\n",
    "We want to use a Feedforward network with 2 Dense Layers, relu-nonlinearity and output softmax using Flax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8af5cf83-b3e2-4a1d-b204-73f383952134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# We import flax.linen as nn\n",
    "# The reason is that flax.nn is old and deprecated and will be removed one day\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7bf8a1ee-844e-4342-8578-6a0df21cc422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Flax model must be a class sub-classing nn.Module\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    # We can have some attributes of the Model. \n",
    "    # Those are considered compile-time constants and must be hashable\n",
    "    # They are useful to define some variables that might be changed often\n",
    "    hidden_width : int = 1024\n",
    "    \"\"\"\n",
    "    The width of the hidden dense layers in the neural network.\n",
    "    \"\"\"\n",
    "    n_outputs : int = 10\n",
    "    \"\"\"\n",
    "    Number of output classes for the classifier \n",
    "    \"\"\"\n",
    "    \n",
    "    # The body of the model must be defined using the `@nn.compact` decorator.\n",
    "    # Just think of it as boilerplate, and if you are curious, check out\n",
    "    # Flax documentation\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        This function should evaluate the result of the model for an input image\n",
    "        x or a batch of images x.\n",
    "        \n",
    "        x has shape (28,28,1) or (N, 28, 28, 1)\n",
    "        \"\"\"\n",
    "        # we first ensure a single image is a 4-tensor\n",
    "        if x.ndim == 3:\n",
    "            x = x.reshape((1, ) + x.shape)\n",
    "            \n",
    "        # We first \"vectorize\" the image\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        \n",
    "        # First dense layer\n",
    "        x = nn.Dense(features=self.hidden_width)(x)\n",
    "        # First nonlinear activation function\n",
    "        x = nn.relu(x)\n",
    "        #x = nn.Dense(features=self.hidden_width)(x)\n",
    "        #x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.n_outputs)(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1324af-5409-4a2c-9fc3-1ae9e09e009b",
   "metadata": {},
   "source": [
    "Let's initialize the model:\n",
    " \n",
    " - We need a seed for the RNG that generates the initial weights\n",
    " - We need a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "add7d9bd-8028-43e0-b62f-d1c8f05b0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "model = Model(hidden_width = 1024, n_outputs=10)\n",
    "\n",
    "key = jax.random.PRNGKey(seed)\n",
    "sample_input = jnp.ones([1, 28, 28, 1])\n",
    "\n",
    "pars = model.init(key, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604bf44-3b6e-4550-93bf-af5253a50364",
   "metadata": {},
   "source": [
    "we can inspect the parameters `pars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a7d79701-b6c0-4207-aab6-d1c9473856f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    params: {\n",
       "        Dense_0: {\n",
       "            kernel: DeviceArray([[ 0.06272361, -0.04523007,  0.04455307, ...,  0.0401537 ,\n",
       "                           0.04866179, -0.05893217],\n",
       "                         [ 0.03216646, -0.05071622,  0.01560513, ..., -0.00933223,\n",
       "                          -0.00218637,  0.01502309],\n",
       "                         [ 0.06411006, -0.0392851 , -0.02909053, ...,  0.01578827,\n",
       "                          -0.02766293,  0.0776424 ],\n",
       "                         ...,\n",
       "                         [ 0.01668577,  0.00019089,  0.02212064, ..., -0.01364938,\n",
       "                          -0.00778654, -0.01584569],\n",
       "                         [-0.01295255,  0.00911052,  0.00867082, ...,  0.02317737,\n",
       "                          -0.01509016, -0.01241465],\n",
       "                         [ 0.01655648,  0.04822065,  0.01358693, ..., -0.0194821 ,\n",
       "                          -0.00854595,  0.01909487]], dtype=float32),\n",
       "            bias: DeviceArray([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       "        },\n",
       "        Dense_1: {\n",
       "            kernel: DeviceArray([[-0.0314371 ,  0.00309207, -0.02992933, ..., -0.0403144 ,\n",
       "                           0.034722  , -0.04977578],\n",
       "                         [ 0.04734345, -0.0380396 , -0.01267887, ..., -0.0117529 ,\n",
       "                          -0.0470979 , -0.03807784],\n",
       "                         [-0.01505996,  0.01678214,  0.01899202, ..., -0.0485573 ,\n",
       "                           0.0563934 ,  0.00642153],\n",
       "                         ...,\n",
       "                         [ 0.00970839,  0.03326492, -0.03198652, ..., -0.023723  ,\n",
       "                          -0.02472805, -0.02167386],\n",
       "                         [-0.00639112, -0.04331256,  0.04033599, ...,  0.03074743,\n",
       "                          -0.00257638,  0.06517929],\n",
       "                         [-0.00433151, -0.01294066, -0.01874469, ..., -0.00766201,\n",
       "                          -0.04973738, -0.00242333]], dtype=float32),\n",
       "            bias: DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b3e0b121-050c-443e-ac7f-9c639b2fb4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.07704171, 0.08986449, 0.07054991, 0.04636909, 0.30741608,\n",
       "              0.064256  , 0.10086796, 0.06952595, 0.10017835, 0.07393045]],            dtype=float32)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample application:\n",
    "jnp.exp(model.apply(pars, jnp.ones([1, 28, 28, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ebdbb9-8e06-4620-89f8-572f752ff73e",
   "metadata": {},
   "source": [
    "## 3 - Writing the loss function\n",
    "\n",
    "We now want to take as a loss function the distance between the _predicted_ probability given by the model $q_W^{(i)}(x)$ and the actualy probabilith $p^{(i)}(x)$.\n",
    "\n",
    "The actual probability is a delta function: it is zero for every label except for the correct one, for which it is 1.\n",
    "\n",
    "To perform this, we can use one-hot encoding, which takes an integer value in $i\\in[0..K]$ and returns a vector in $R^K$ where only the i-th component is 1 and the other are zero: $v_j = \\delta_{i,j}$.\n",
    "\n",
    "See the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d168c699-dbc5-4f84-9f1f-40511e35050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 becomes: [1. 0. 0. 0. 0.]\n",
      "1 becomes: [0. 1. 0. 0. 0.]\n",
      "2 becomes: [0. 0. 1. 0. 0.]\n",
      "3 becomes: [0. 0. 0. 1. 0.]\n",
      "4 becomes: [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"{i} becomes: {jax.nn.one_hot(i, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72691d-9a4e-4826-a042-67b0aaa3238e",
   "metadata": {},
   "source": [
    "For the loss function, i'll draw from my vast knowledge of loss functions (aka: [here](https://optax.readthedocs.io/en/latest/api.html)) and choose `optax.softmax_cross_entropy`\n",
    "\n",
    "`?optax.softmax_cross_entropy`\n",
    "> Computes the softmax cross entropy between sets of logits and labels.\n",
    ">\n",
    ">Measures the probability error in discrete classification tasks in which\n",
    ">the classes are mutually exclusive (each entry is in exactly one class).\n",
    ">For example, each CIFAR-10 image is labeled with one and only one label:\n",
    ">an image can be a dog or a truck, but not both.\n",
    ">\n",
    ">References:\n",
    "> [Goodfellow et al, 2016](http://www.deeplearningbook.org/contents/prob.html)\n",
    ">\n",
    ">Args:\n",
    ">\n",
    ">  logits: unnormalized log probabilities.\n",
    ">\n",
    ">  labels: a valid probability distribution (non-negative, sum to 1), e.g a\n",
    ">    one hot encoding of which class is the correct one for each input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e4112499-6b6f-445e-bd18-22fd5b0b2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function that we will use\n",
    "def cross_entropy(*, logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e90668ed-0090-446a-81d3-4f6e1763b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our cost function that we will be optimising\n",
    "def loss_fn(params, images, labels):\n",
    "    # compute the output of the model\n",
    "    logits = model.apply({'params': params}, images)\n",
    "    return cross_entropy(logits=logits, labels=labels)\n",
    "\n",
    "# An utility function to compute some metrics during the training\n",
    "def compute_metrics(*, logits, labels):\n",
    "    loss = cross_entropy(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5915221-3875-46a9-b6dd-1b32b17e38c0",
   "metadata": {},
   "source": [
    "We then need a function to keep the training state in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "50082ccb-9022-496a-8898-f2b645116347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = model.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dfa1c-53cb-4b6a-a177-2a7233b87853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5f6b6254-da8a-4bd5-ad56-15b13a3c2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    _loss_fn = partial(loss_fn, images=batch['image'], labels=batch['label'])\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(_loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    \n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    logits = model.apply({'params': state.params}, batch['image'])\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    \n",
    "    return state, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4d0ec7de-f082-4276-96e6-86c59712ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "  logits = model.apply({'params': params}, batch['image'])\n",
    "  return compute_metrics(logits=logits, labels=batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e2f17cf0-198d-4d57-88d9-de60e6e76492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng, *, max_steps=None):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    \n",
    "    # total number of training images\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    \n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    # Truncate the number of steps (used to speed up training)\n",
    "    if max_steps is not None:\n",
    "        steps_per_epoch = min(steps_per_epoch, max_steps)\n",
    "\n",
    "\n",
    "    # generate a random permutation of the indices to shuffle the training\n",
    "    # dataset, and reshape it to a set of batches.\n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    \n",
    "    # execute the training step for every mini-batch\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    # compute mean of metrics across each batch in epoch.\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "            for k in batch_metrics_np[0]}\n",
    "\n",
    "    return state, epoch_metrics_np\n",
    "\n",
    "def eval_model(params, test_ds):\n",
    "    \"\"\"\n",
    "    evaluate the performance of the model on the test dataset\n",
    "    \"\"\"\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6e7263bc-b1f0-4a71-8b2a-ff19daf8257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7f0eee07-7262-49df-82cb-df181c9ed707",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7c1094b1-4937-4eb0-a51f-418f5d3dfc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(init_rng, learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0b195b90-b838-4b75-96a1-28b5302cf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a077215-b821-45cf-8747-cd7154f4351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                  | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "metrics = {\"test_loss\" : [], \"test_accuracy\": [], \"train_loss\":[], \"train_accuracy\":[]}\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    state, train_metrics = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    # Evaluate on the test set after each training epoch\n",
    "    test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "    print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (epoch, train_metrics['loss'], train_metrics['accuracy'] * 100))\n",
    "    print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (epoch, test_loss, test_accuracy * 100))\n",
    "\n",
    "    # save data\n",
    "    metrics[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "    metrics[\"train_accuracy\"].append(train_metrics[\"accuracy\"])\n",
    "    metrics[\"test_loss\"].append(test_loss)\n",
    "    metrics[\"test_accuracy\"].append(test_accuracy)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefca0cb-80ed-43df-84de-1b4073a84d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metrics[\"train_loss\"], label=\"train\")\n",
    "plt.plot(metrics[\"test_loss\"], label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c648e44-94ef-4dab-a575-6680d080ea64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be20751-f944-4a18-9a4b-6442eabcdff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49e168-7200-40ac-a05d-d5bd43616d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9744c-b912-4099-aee7-2e513c3c0f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461cb1d-183d-4fb0-a9ba-a72842b37e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab39fe-4c9e-4fa9-8448-c5364c469af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e722e-8b7a-4459-913f-53635efa273b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae58e9-826f-437f-b497-d4174885d461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML Teaching)",
   "language": "python",
   "name": "teach-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
